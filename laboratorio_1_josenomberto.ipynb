{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josenomberto/UTEC-CDIAV3-MCD8009/blob/main/laboratorio_1_josenomberto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149c716d-2979-4493-96f0-3be68f821afa",
      "metadata": {
        "id": "149c716d-2979-4493-96f0-3be68f821afa"
      },
      "source": [
        "# MCD8009: Data Discovery - Laboratorio 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004c2f66",
      "metadata": {
        "id": "004c2f66"
      },
      "source": [
        "**Integrantes**\n",
        "\n",
        "| N° | Código | Nombres |  Contribución (0% - 100%) |\n",
        "|----|--------|---------|---------------------------|\n",
        "| 1  |        | José Carlos Nomberto        | 100%                           |\n",
        "| 2  |        |         |                           |\n",
        "| 3  |        |         |                           |\n",
        "| 4  |        |         |                           |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5de1bf7c",
      "metadata": {
        "id": "5de1bf7c"
      },
      "source": [
        "### Indicaciones\n",
        "\n",
        "- El laboratorio podrá resolverse de manera **individual o en equipos de hasta cuatro (4) personas**. Deberán completar los datos de todos los integrantes, y **una sola persona realizará la entrega del archivo ipynb**.\n",
        "\n",
        "- Salvo que se indique explícitamente lo contrario, no se prohibe el uso de herramientas de Inteligencia Artificial Generativa, siempre que los integrantes comprendan y puedan explicar el proceso y los resultados obtenidos. **Las respuestas no deben consistir en transcripciones literales de resultados generados por estas herramientas, sino evidenciar comprensión del tema por parte del estudiante o del equipo.**\n",
        "\n",
        "- En caso de utilizar herramientas de IA Generativa, cada equipo es responsable de verificar la coherencia de las respuestas presentadas. Si se detectan errores, inconsistencias o falta de comprensión, la pregunta podrá ser anulada sin derecho a reclamo.\n",
        "\n",
        "- En todos los casos, deberá completarse la **Declaración de Uso de IA Generativa.**\n",
        "\n",
        "- Pueden agregar libremente celdas de código o de Markdown según lo consideren conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c12852",
      "metadata": {
        "id": "e7c12852"
      },
      "source": [
        "### Declaración de uso de IA Generativa\n",
        "- Indicar de manera breve la(s) herramienta(s) y/o modelo(s) de IA Generativa utilizados, especificando en qué pregunta(s) se emplearon y con qué propósito.\n",
        "- En caso no se haya usado, también indicarlo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd6cd0af",
      "metadata": {
        "id": "dd6cd0af"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "739d301c",
      "metadata": {
        "id": "739d301c"
      },
      "source": [
        "## INICIO DEL LABORATORIO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b7e23a7",
      "metadata": {
        "id": "3b7e23a7"
      },
      "source": [
        "### Parte 1: Frameworks de la industria: CRISP-DM [Sin uso de IA generativa] (3 puntos)\n",
        "\n",
        "CRISP-DM suele presentarse como un framework de Ciencia de Datos, pero muchas de sus fases se aplican también en proyectos de analytics, BI y toma de decisiones data-driven, incluso sin usar modelos de machine learning. ¿En qué medida reconoce que, consciente o inconscientemente, ha trabajado siguiendo las fases de CRISP-DM en su experiencia profesional?\n",
        "Conversen entre los integrantes del equipo y presenten solo 1 caso.\n",
        "\n",
        "\n",
        "Contraste su forma real de trabajo con las fases del framework:\n",
        "\n",
        "- Business Understanding\n",
        "\n",
        "- Data Understanding\n",
        "\n",
        "- Data Preparation\n",
        "\n",
        "- Modeling (si aplica)\n",
        "\n",
        "- Evaluation\n",
        "\n",
        "- Deployment / uso en negocio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ce3010",
      "metadata": {
        "id": "d8ce3010"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b5c7cfe",
      "metadata": {
        "id": "5b5c7cfe"
      },
      "source": [
        "### Parte 2: Tipos de analítica [Sin uso de IA generativa] (3 puntos)\n",
        "\n",
        "**Caso: Análisis de datos para una tienda en línea**\n",
        "\n",
        "Imagine que es consultor de análisis de datos y has sido contratado por una tienda en línea que vende productos electrónicos. La tienda desea aprovechar al máximo los datos recopilados de sus clientes y mejorar su estrategia de marketing, la experiencia del cliente y la toma de decisiones comerciales. Tu objetivo es aplicar diferentes tipos de análisis de datos para obtener información valiosa y proporcionar recomendaciones basadas en los resultados obtenidos.\n",
        "\n",
        "La tienda en línea ha recopilado una amplia variedad de datos sobre sus clientes y las transacciones realizadas. Entro los datos demográficos con los que cuenta tenemos: edad, género, ubicación geográfica, etc. Asimismo, cuenta con datos de navegación por el sitio web en donde se puede ver los productos vistos, los comentarios de los clientes, entre otros.\n",
        "\n",
        "Tu misión es utilizar diferentes enfoques de análisis de datos para ayudar a la tienda a comprender mejor a sus clientes, optimizar sus operaciones y tomar decisiones informadas. En función de la información dada y supuestos que pueda añadir, realice los 4 Tipos de Data Analytics estudiados comentando qué deberíamos hacer en cada uno de ellos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff1bbea",
      "metadata": {
        "id": "cff1bbea"
      },
      "source": [
        "- **Analítica Descriptiva**\n",
        "\n",
        "...\n",
        "\n",
        "- **Analítica Diagnóstico**\n",
        "\n",
        "...\n",
        "\n",
        "- **Analítica Predictiva**\n",
        "\n",
        "...\n",
        "\n",
        "- **Analítica Prescriptiva**\n",
        "\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9fcc9fa",
      "metadata": {
        "id": "d9fcc9fa"
      },
      "source": [
        "### Parte 3: Lectura de datos (5 puntos)\n",
        "\n",
        "En clase vimos cómo leer datos desde distintas fuentes. En la industria es muy común recibir archivos planos como CSV; sin embargo, con frecuencia no se conoce de antemano:\n",
        "\n",
        "- El *encoding* del archivo.\n",
        "- El delimitador utilizado (`;`, `,`, `|`, `\\t`, etc.).\n",
        "- La existencia de líneas \"basura\" al inicio (metadatos, comentarios, encabezados duplicados, etc.).\n",
        "\n",
        "El objetivo es leer correctamente los datos del archivo `lab1.csv` sin modificar el archivo original, resolviendo las incertidumbres mencionadas.\n",
        "\n",
        "Antes de programar, lea la documentación de [chardet](https://chardet.readthedocs.io/en/latest/) y de [csv.Sniffer](https://docs.python.org/es/3/library/csv.html#csv.Sniffer)\n",
        "\n",
        "Adicional a la implementación del código, imprima el head del archivo y responda las preguntas solicitadas.\n",
        "\n",
        "#### Funciones a implementar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chardet\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def detectar_encoding(nombre_archivo, longitud_muestra):\n",
        "    \"\"\"\n",
        "    Detecta la codificación del archivo.\n",
        "    Argumentos:\n",
        "      nombre_archivo: nombre del archivo a leer\n",
        "      longitud_muestra: número de bytes a leer para la muestra\n",
        "    Retorna:\n",
        "      codificacion: diccionario con la codificación detectada\n",
        "    \"\"\"\n",
        "    with open(nombre_archivo, 'rb') as archivo:\n",
        "        codificacion = chardet.detect(archivo.read(longitud_muestra))\n",
        "\n",
        "    return codificacion\n",
        "\n",
        "\n",
        "def detectar_delimitador(nombre_archivo, longitud_muestra, codificacion, skip_lines):\n",
        "    \"\"\"\n",
        "    Detecta el delimitador del archivo CSV.\n",
        "    Argumentos:\n",
        "      nombre_archivo: nombre del archivo a leer\n",
        "      longitud_muestra: número de bytes a leer para la muestra\n",
        "      codificacion: codificación del archivo\n",
        "      skip_lines: número de líneas iniciales a ignorar\n",
        "    Retorna:\n",
        "      delimitador: delimitador del archivo\n",
        "    \"\"\"\n",
        "    with open(nombre_archivo, 'r', newline='', encoding=codificacion) as archivo:\n",
        "        for _ in range(skip_lines):\n",
        "            next(archivo)\n",
        "        archivo_muestra = archivo.read(longitud_muestra)\n",
        "        archivo.seek(0)\n",
        "        delimitador = csv.Sniffer().sniff(archivo_muestra, delimiters=[',', ';', '|', '\\t']).delimiter\n",
        "\n",
        "    return delimitador\n",
        "\n",
        "\n",
        "def leer_csv_inteligente(ruta_archivo, skip_lines=0):\n",
        "    \"\"\"\n",
        "    Lee un archivo CSV detectando automáticamente:\n",
        "    - El encoding\n",
        "    - El delimitador\n",
        "\n",
        "    Parámetros:\n",
        "    - ruta_archivo: ruta al archivo CSV\n",
        "    - skip_lines: número de líneas iniciales a ignorar\n",
        "\n",
        "    Retorna:\n",
        "    - pandas.DataFrame\n",
        "    \"\"\"\n",
        "    longitud_muestra = 600\n",
        "\n",
        "    # 1. Detectando la codificación del archivo\n",
        "    print(\"\\n\")\n",
        "    print(f\"Detectando la codificación del archivo ... \")\n",
        "    encoding = detectar_encoding(ruta_archivo, longitud_muestra)\n",
        "    print(f\"   La codificación del archivo '{ruta_archivo}' es:  {encoding['encoding']}\")\n",
        "    print(f\"   El nivel de confianza para la codificación detectada es:  {encoding['confidence']}\")\n",
        "\n",
        "    # 2. Detectando el delimitador del archivo\n",
        "    print(\"\\n\")\n",
        "    print(f\"Detectando el delimitador del archivo ... \")\n",
        "    delimitador = detectar_delimitador(ruta_archivo, longitud_muestra, encoding['encoding'], skip_lines)\n",
        "    print(f\"   El delimitador del archivo '{ruta_archivo}' es:  '{delimitador}'\")\n",
        "\n",
        "    # 3. Abriendo el archivo con codificacion, delimitador y saltando lineas\n",
        "    try:\n",
        "        # Leer archivo en DataFrame\n",
        "        print(\"\\n\")\n",
        "        print(f\"Leyendo el archivo ... \")\n",
        "        df = pd.read_csv(\n",
        "            ruta_archivo,\n",
        "            sep=delimitador,\n",
        "            #sep='|',\n",
        "            encoding=encoding['encoding'],\n",
        "            skiprows=skip_lines\n",
        "        )\n",
        "        # Imprime la cabecera del DataFrame\n",
        "        print(f\"Imprimiendo cabecera del archivo ... \")\n",
        "        print(\"\\n\")\n",
        "        print(df.head())\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Archivo '{ruta_archivo}' no encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Tr11IhdC_9po"
      },
      "id": "Tr11IhdC_9po",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura inteligente de archivo csv\n",
        "nombre_archivo = \"lab1.csv\"\n",
        "skip_lines = 1\n",
        "print(f\"Lectura interligente de archivo '{nombre_archivo}' con '{skip_lines}' línea(s) inicial(es) a ignorar:\")\n",
        "archivo_df = leer_csv_inteligente(nombre_archivo, skip_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtoL609MHqgQ",
        "outputId": "eb33a14d-83f5-4f91-a3e4-23fab899614a"
      },
      "id": "EtoL609MHqgQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lectura interligente de archivo 'lab1.csv' con '1' línea(s) inicial(es) a ignorar:\n",
            "\n",
            "\n",
            "Detectando la codificación del archivo ... \n",
            "   La codificación del archivo 'lab1.csv' es:  ISO-8859-1\n",
            "   El nivel de confianza para la codificación detectada es:  0.73\n",
            "\n",
            "\n",
            "Detectando el delimitador del archivo ... \n",
            "   El delimitador del archivo 'lab1.csv' es:  '|'\n",
            "\n",
            "\n",
            "Leyendo el archivo ... \n",
            "Imprimiendo cabecera del archivo ... \n",
            "\n",
            "\n",
            "   id nombre apellido  edad    monto    estado\n",
            "0   1   José   García    20  4210.24    ACTIVO\n",
            "1   2  María    Pérez    44  3950.89  INACTIVO\n",
            "2   3   Peña    López    56  2890.01    ACTIVO\n",
            "3   4   Luis  Sánchez    50  1962.01    ACTIVO\n",
            "4   5    Ana   Torres    51  4075.63  INACTIVO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0881a668",
      "metadata": {
        "id": "0881a668"
      },
      "source": [
        "\n",
        "#### Requisitos técnicos\n",
        "\n",
        "La solución debe cumplir con lo siguiente:\n",
        "\n",
        "- Detectar el encoding del archivo utilizando `chardet`.\n",
        "- Detectar el delimitador del archivo CSV utilizando `csv.Sniffer`.\n",
        "- Incluir el argumento `skip_lines` como el número de líneas iniciales a ignorar.\n",
        "- Devolver los datos en una estructura `pandas.DataFrame`.\n",
        "- Optimizar la detección del encoding y delimitador (tomar un sample del archivo, no un full read)\n",
        "\n",
        "\n",
        "#### Preguntas teóricas\n",
        "\n",
        "Responda brevemente las siguientes preguntas:\n",
        "\n",
        "1. ¿Qué problema resuelve **chardet**?  \n",
        "   ¿Qué información devuelve el método `chardet.detect()`?\n",
        "\n",
        "2. ¿Para qué sirve **csv.Sniffer**?  \n",
        "   ¿Cuáles son sus principales limitaciones?  \n",
        "   ¿Qué sucede si `csv.Sniffer` detecta incorrectamente el delimitador?\n",
        "\n",
        "3. ¿Cuál era el encoding y el delimitador del archivo `lab1.csv`?\n",
        "\n",
        "4. ¿Por qué no siempre es una buena práctica confiar únicamente en la detección automática?\n",
        "\n",
        "5. En la función propuesta, el argumento `skip_lines` se determina de manera manual.  \n",
        "   ¿Qué alternativas podrían implementarse para automatizar la detección de las líneas a ignorar?\n",
        "\n",
        "6. Desde un criterio de negocio o de mejora de procesos, ¿qué mejora general propondría para gestionar de forma más eficiente la recepción de este tipo de archivos “problemáticos”?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESPUESTAS:**\n",
        "\n",
        "1.   La libreria chardet sirve para detectar la codificacion de un archivo.\n",
        "Devuelve un diccionario con la información de la codificacion detectada y el nivel de confianza para la detección.\n",
        "\n",
        "2.   La libreria csv.Sniffer sirve para detectar el formato de un archivo CSV analizando una muestra del texto. Las principales limitaciones son:\n",
        "  *   no detecta los caracteres de escape de secuencia\n",
        "  *   resultados inconsistentes segun el orden de los datos\n",
        "\n",
        "      Si csv.Sniffer detecta incorrectamente el delimitador, la importacion del archivo fallara causando que los datos no esten bien estructurados o se carguen todos en una misma columna\n",
        "\n",
        "3.   El encoding del archivo es 'ISO-8859-1', y el delimtador '|'.\n",
        "\n",
        "4.   No es bueno solo confiar en la detección automática ya que es suceptible a errores de interferencia para detectar el tipo de datos (por ejemplo, fechas), detección incorrecta en archivos sin cabecera, el sniffer analiza solamente hasta los primero 2048 bytes lo cual podria no ser suficiente, etc.\n",
        "\n",
        "5.   Alternativas al uso del parametro skip_lines definido manualmente:\n",
        "\n",
        "*   Leer el archivo linea por linea\n",
        "*   Identificar lineas con espacios en blanco\n",
        "*   Ignorar lineas en blanco\n",
        "*   Ignorar lineas comentadas (#)\n",
        "\n",
        "6.   Mejoras en el proceso:\n",
        "\n",
        "*   Definir estructura (formato) para archivos a leer\n",
        "*   Estandarizar el encoding a uno estandar para todos los archivos\n",
        "*   Definir cabecera de archivos para uniformizar y adaptar aquellos que no tengan cabecera\n",
        "*   Mostrar métricas en la lectura de archivos, como por ejemplo archivos \"limpios\" vs archivos \"sucios\",\n",
        "\n"
      ],
      "metadata": {
        "id": "DBrVFDBSH1qY"
      },
      "id": "DBrVFDBSH1qY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2cf9382",
      "metadata": {
        "id": "c2cf9382"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "86727bef-7dad-4731-bf45-98733e3b9f2b",
      "metadata": {
        "id": "86727bef-7dad-4731-bf45-98733e3b9f2b"
      },
      "source": [
        "### Parte 4: Webscrapping (5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ec062ad-fbad-46a0-bf67-2c84af84723e",
      "metadata": {
        "id": "3ec062ad-fbad-46a0-bf67-2c84af84723e"
      },
      "source": [
        "En clase vimos cómo aplicar webscraping. Ahora es momento de practicar. Puede usar la(s) librería(s) que considere más conveniente para esta casuística.\n",
        "\n",
        "La actividad consiste en obtener un dataframe de esta página: https://www.imdb.com/chart/top/, la cual muestra las 250 mejores películas de IMDb.\n",
        "\n",
        "Los campos a extraer son los siguientes, con el siguiente formato (se muestra un registro a modo de ejemplo):\n",
        "\n",
        "| rankings | titulo           | anio  | duracion_minutos   | clasificacion | calificacion |  votos_millones       |\n",
        "|----------|------------------|-------|--------------------|---------------|--------------|-----------------------|\n",
        "| 1        | Sueño de fuga    | 1994  |    142             |       B       |    9.3       |  2.2                  |\n",
        "\n",
        "- Note que la duración se ha convertido a minutos y que los votos han sido transformados a millones (como variable numérica).\n",
        "- Aplique buenas prácticas de webscrapping (ej: Uso de User-Agent en los headers HTTP, uso de timeout en la petición, manejo de errores HTTP, etc.)\n",
        "- Sustente brevemente las razones por las que empleó dicha(s) librería(s) de webscrapping.\n",
        "- Finalmente, imprimir el head del dataframe, además, exportar dicho dataframe en un archivo llamado `top250_imdb.csv`. No adjunte el archivo en su entrega, pero debe realizar el código para generarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "206b8408",
      "metadata": {
        "id": "206b8408"
      },
      "outputs": [],
      "source": [
        "# 1. Install and import required modules\n",
        "\n",
        "#!pip install curl_cffi\n",
        "#import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from curl_cffi import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Access HTML Content\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n",
        "headers = {\n",
        "    \"User-Agent\": user_agent,\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "    'Connection': 'keep-alive',\n",
        "    \"Referer\": \"https://www.google.com/\"\n",
        "}\n",
        "print(f\"\\n1. Target URL for Web Scrapping: {url}\")\n",
        "try:\n",
        "    # Use the 'chrome110' impersonate string (check documentation for latest versions)\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        headers=headers,\n",
        "        impersonate=\"chrome110\", # This handles the specific TLS/HTTP2 fingerprint\n",
        "        timeout=10\n",
        "    )\n",
        "    print(f\"\\n2. Response status code: {response.status_code}\")\n",
        "    print(f\"   Content Length: {len(response.content)} bytes\")\n",
        "    #print(f\"\\n4. HTML Text:\")\n",
        "    #print(response.text)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eeod_Zu7sR0H",
        "outputId": "69df21f3-aa70-4f72-8c76-e273b47f4b1d"
      },
      "id": "eeod_Zu7sR0H",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Target URL for Web Scrapping: https://www.imdb.com/chart/top/\n",
            "\n",
            "2. Response status code: 200\n",
            "   Content Length: 1771053 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Parse HTML with Beautiful Soup\n",
        "\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")"
      ],
      "metadata": {
        "id": "-G_eaoq_wQjW"
      },
      "id": "-G_eaoq_wQjW",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import template\n",
        "# 4. Get data from\n",
        "\n",
        "movies = soup.find_all(\"li\", class_=\"ipc-metadata-list-summary-item\")\n",
        "movie_data = []\n",
        "\n",
        "for movie in movies:\n",
        "    ranking = movie.find(\"div\", class_=\"ipc-signpost__text\").text\n",
        "    title = movie.find(\"h3\", class_=\"ipc-title__text\").text.strip()\n",
        "    title_metadata = movie.find_all(\"span\", class_=\"cli-title-metadata-item\")\n",
        "    year = title_metadata[0].text.strip()\n",
        "    duration = title_metadata[1].text.strip()\n",
        "    classification = title_metadata[2].text.strip()\n",
        "    #year = movie.find(\"span\", class_=\"cli-title-metadata-item\").text.strip()\n",
        "    rating = movie.find(\"span\", class_=\"ipc-rating-star--rating\").text.strip()\n",
        "    votes = movie.find(\"span\", class_=\"ipc-rating-star--voteCount\").text.strip()\n",
        "    print(f\"{ranking} | {title} | {year} | {duration} | {classification} | {rating} | {votes}\")\n"
      ],
      "metadata": {
        "id": "FHSUj_ZBDHrY",
        "outputId": "f3652902-9276-46ff-e5c8-59a4332ac663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FHSUj_ZBDHrY",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#1 | The Shawshank Redemption | 1994 | 2h 22m | R | 9.3 | (3.2M)\n",
            "#2 | The Godfather | 1972 | 2h 55m | R | 9.2 | (2.2M)\n",
            "#3 | The Dark Knight | 2008 | 2h 32m | PG-13 | 9.1 | (3.1M)\n",
            "#4 | The Godfather Part II | 1974 | 3h 22m | R | 9.0 | (1.5M)\n",
            "#5 | 12 Angry Men | 1957 | 1h 36m | Approved | 9.0 | (972K)\n",
            "#6 | The Lord of the Rings: The Return of the King | 2003 | 3h 21m | PG-13 | 9.0 | (2.1M)\n",
            "#7 | Schindler's List | 1993 | 3h 15m | R | 9.0 | (1.6M)\n",
            "#8 | The Lord of the Rings: The Fellowship of the Ring | 2001 | 2h 58m | PG-13 | 8.9 | (2.2M)\n",
            "#9 | Pulp Fiction | 1994 | 2h 34m | R | 8.8 | (2.4M)\n",
            "#10 | The Good, the Bad and the Ugly | 1966 | 2h 58m | R | 8.8 | (883K)\n",
            "#11 | The Lord of the Rings: The Two Towers | 2002 | 2h 59m | PG-13 | 8.8 | (1.9M)\n",
            "#12 | Forrest Gump | 1994 | 2h 22m | PG-13 | 8.8 | (2.5M)\n",
            "#13 | Fight Club | 1999 | 2h 19m | R | 8.8 | (2.6M)\n",
            "#14 | Inception | 2010 | 2h 28m | PG-13 | 8.8 | (2.8M)\n",
            "#15 | Star Wars: Episode V - The Empire Strikes Back | 1980 | 2h 4m | PG | 8.7 | (1.5M)\n",
            "#16 | The Matrix | 1999 | 2h 16m | R | 8.7 | (2.2M)\n",
            "#17 | Goodfellas | 1990 | 2h 25m | R | 8.7 | (1.4M)\n",
            "#18 | Interstellar | 2014 | 2h 49m | PG-13 | 8.7 | (2.5M)\n",
            "#19 | One Flew Over the Cuckoo's Nest | 1975 | 2h 13m | R | 8.6 | (1.1M)\n",
            "#20 | Se7en | 1995 | 2h 7m | R | 8.6 | (2M)\n",
            "#21 | It's a Wonderful Life | 1946 | 2h 10m | PG | 8.6 | (551K)\n",
            "#22 | The Silence of the Lambs | 1991 | 1h 58m | R | 8.6 | (1.7M)\n",
            "#23 | Seven Samurai | 1954 | 3h 27m | Not Rated | 8.6 | (399K)\n",
            "#24 | Saving Private Ryan | 1998 | 2h 49m | R | 8.6 | (1.6M)\n",
            "#25 | The Green Mile | 1999 | 3h 9m | R | 8.6 | (1.5M)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d29b9f7-cf0d-492b-a330-8e1b4f75a819",
      "metadata": {
        "id": "3d29b9f7-cf0d-492b-a330-8e1b4f75a819"
      },
      "source": [
        "### Parte 5: APIs (4 puntos)\n",
        "\n",
        "En esta actividad se utilizará la API del BCRP para construir un DataFrame a partir de diversas series de datos.\n",
        "En ese sentido, debe completar la función `obtener_datos_bcrp`. Como apoyo, se proporciona un ejemplo del comportamiento esperado del resultado, así como la URL base que se emplea para realizar las consultas en cada caso.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c04400",
      "metadata": {
        "id": "59c04400"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "def obtener_datos_bcrp(codigos_series, fecha_inicio=None, fecha_fin=None):\n",
        "    \"\"\"\n",
        "    Obtiene datos de la API del BCRP y los convierte a DataFrame\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    codigos_series : str o list\n",
        "        Código(s) de las series a consultar (ej: 'PN01207PM' o ['PD04637PD', 'PD04638PD'])\n",
        "    fecha_inicio : str, opcional\n",
        "        Fecha de inicio en formato 'YYYY-M' para series mensuales o 'YYYY-M-D' para series diarias\n",
        "    fecha_fin : str, opcional\n",
        "        Fecha de fin en formato 'YYYY-M' para series mensuales o 'YYYY-M-D' para series diarias\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    DataFrame con los datos obtenidos y los códigos de series como nombres de columnas\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbc0a02",
      "metadata": {
        "id": "cdbc0a02",
        "outputId": "4d17cd6f-aa79-4509-a16d-f0aa18b5cded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Consultando: https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PN01207PM/json\n",
            "    periodo  PN01207PM\n",
            "0  Dic.2023   3.733942\n",
            "1  Ene.2024   3.740743\n",
            "2  Feb.2024   3.827938\n",
            "3  Mar.2024   3.708989\n",
            "4  Abr.2024   3.715032\n",
            "Consultando: https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04638PD/json/2024-11-1/2024-12-31\n",
            "     periodo  PD04637PD  PD04638PD\n",
            "0  04.Nov.24   3.766333   3.768667\n",
            "1  05.Nov.24   3.772500   3.774833\n",
            "2  06.Nov.24   3.781500   3.784833\n",
            "3  07.Nov.24   3.752167   3.755833\n",
            "4  08.Nov.24   3.767167   3.769500\n"
          ]
        }
      ],
      "source": [
        "## NO MODIFICAR - EJEMPLOS DE USO ##\n",
        "## Debe funcionar correctamente una vez que la función esté implementada ##\n",
        "\n",
        "## Ejemplo 1: Consulta simple - Una serie\n",
        "# Tipo de cambio interbancario promedio mensual\n",
        "df1 = obtener_datos_bcrp('PN01207PM')\n",
        "print(\"Consultando: https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PN01207PM/json\")\n",
        "print(df1.head())\n",
        "\n",
        "## Ejemplo 2: Múltiples series con rango de fechas\n",
        "#Tipo de cambio interbancario diario - Compra y Venta\n",
        "series = ['PD04637PD', 'PD04638PD']\n",
        "df2 = obtener_datos_bcrp(series, fecha_inicio='2024-11-1', fecha_fin='2024-12-31')\n",
        "print(\"Consultando: https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04638PD/json/2024-11-1/2024-12-31\")\n",
        "print(df2.head())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}